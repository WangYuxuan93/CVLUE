train_file: ['../../new_dataset/cvlue_new/vd/cvlue_vd_train_new.json',]
valid_file: ['../../new_dataset/cvlue_new/vd/cvlue_vd_val_new.json']



train_answer_list: '../../new_dataset/cvlue_new/vd/cvlue_vd_train_answers.json'
valid_answer_list: '../../new_dataset/cvlue_new/vd/cvlue_vd_val_answers.json'
test_answer_list: '../../new_dataset/cvlue_new/vd/cvlue_vd_test_answers.json'
vqa_root: '../../pics'


# zero-shot test set

test_file: {
  'ch': [ '../../new_dataset/cvlue_new/vd/cvlue_vd_test_new.json', '../../new_dataset/cvlue_new/vd/cvlue_vd_test_new.json']
}



## Vision Encoder
vision_config: 'configs/config_swinB_384.json'

use_clip_vit: False
#image_res: 384
#patch_size: 16

use_swin: True
image_res: 384
patch_size: 32


## Text Encoder (& Cross Encoder)
text_encoder: 'data/xlm-roberta-large'
text_num_hidden_layers: 12


## Training
num_dec_layers: 6
batch_size_train: 16
batch_size_test: 1
max_tokens: 512
k_test: 100
accumulate_steps: 8


## Other Settings
optimizer: {opt: adamW, lr: 3e-5, weight_decay: 0.01, lr_mult: 2}
schedular: {sched: linear, lr: 3e-5, epochs: 10, num_warmup_steps: 0.1}
start_eval: 0  # epoch index


