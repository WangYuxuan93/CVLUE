

train_file: ['../../new_dataset/VG/last_VG_train_new.json']
test_file: ['../../new_dataset/VG/last_VG_test_new.json']
val_file: ['../../new_dataset/VG/last_VG_val_new.json']


refcoco_data: '../../pics/'

image_root: '../../pics/'

careful_hflip: True  # first check whether 'left' or 'right' in captions

## Vision Encoder
use_beit_v2: True
vision_config: 'configs/config_beit2_base.json'
image_res: 384
patch_size: 16



## Text Encoder (& Cross Encoder)
model_type: 'CrossViewLM'
text_encoder: 'data/xlm-roberta-base'
text_num_hidden_layers: 12
cross_encoder: 'data/bert-base-uncased'
cross_num_hidden_layers: 6

text_fusion_start_at: 12

text_drop_path_rate: 0.1
# cross_drop_path_rate: 0.1

## Training
batch_size: 32  # xN A100s, i don't remember how many GPUs i used... (i guess either 8 or 16)
max_tokens: 40
accumulate_steps: 4



## Other Settings
optimizer: {opt: adamW, lr: 1e-5, weight_decay: 0.01, lr_mult: 2}
schedular: {sched: linear, epochs: 10, num_warmup_steps: 0.1}







